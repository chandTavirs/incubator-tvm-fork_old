{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, print_function\n",
    "\n",
    "import argparse, json, os, requests, sys, time\n",
    "from io import BytesIO\n",
    "from os.path import join, isfile\n",
    "from PIL import Image\n",
    "\n",
    "from mxnet.gluon.model_zoo import vision\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tvm\n",
    "from tvm import te\n",
    "from tvm import rpc, autotvm, relay\n",
    "from tvm.contrib import graph_runtime, utils, download\n",
    "from tvm.contrib.debugger import debug_runtime\n",
    "from tvm.relay import transform\n",
    "\n",
    "import vta\n",
    "from vta.testing import simulator\n",
    "from vta.top import graph_pack\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from tvm.contrib.download import download_testdata\n",
    "\n",
    "\n",
    "\n",
    "# Make sure that TVM was compiled with RPC=1\n",
    "assert tvm.runtime.enabled(\"rpc\")\n",
    "import os\n",
    "os.environ[\"TVM_BACKTRACE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VTA parameters from the 3rdparty/vta-hw/config/vta_config.json file\n",
    "env = vta.get_env()\n",
    "\n",
    "# Set ``device=arm_cpu`` to run inference on the CPU\n",
    "# or ``device=vta`` to run inference on the FPGA.\n",
    "device = \"vta\"\n",
    "target = env.target if device == \"vta\" else env.target_vta_cpu\n",
    "\n",
    "# Dictionary lookup for when to start/end bit packing\n",
    "pack_dict = {\n",
    "    \"resnet18_v1\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet18\": [\"nn.max_pool2d\", \"nn.adaptive_avg_pool2d\"],\n",
    "    \"resnet34\": [\"nn.max_pool2d\", \"nn.adaptive_avg_pool2d\"],\n",
    "    \"resnet50\": [\"nn.max_pool2d\", \"nn.adaptive_avg_pool2d\"],\n",
    "    \"resnet101\": [\"nn.max_pool2d\", \"nn.adaptive_avg_pool2d\"],\n",
    "    \"vgg11\": [\"nn.max_pool2d\", \"nn.dense\"],\n",
    "    \"vgg16\":    [\"nn.max_pool2d\", \"nn.dense\"],\n",
    "    \"resnet34_v1\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet18_v2\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet34_v2\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet50_v2\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet101_v2\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"mobilenetv2_1.0\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"]\n",
    "}\n",
    "\n",
    "# Name of Gluon model to compile\n",
    "# The ``start_pack`` and ``stop_pack`` labels indicate where\n",
    "# to start and end the graph packing relay pass: in other words\n",
    "# where to start and finish offloading to VTA.\n",
    "#model = \"resnet18_v1\"\n",
    "#assert model in pack_dict\n",
    "model = \"mobilenetv2_1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "__all__ = ['mobilenetv2']\n",
    "\n",
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    \"\"\"\n",
    "    This function is taken from the original tf repo.\n",
    "    It ensures that all layers have a channel number that is divisible by 8\n",
    "    It can be seen here:\n",
    "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    :param v:\n",
    "    :param divisor:\n",
    "    :param min_value:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "def conv_3x3_bn(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def conv_1x1_bn(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = round(inp * expand_ratio)\n",
    "        self.identity = stride == 1 and inp == oup\n",
    "\n",
    "        if expand_ratio == 1:\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.identity:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=1000, width_mult=1.):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        # setting of inverted residual blocks\n",
    "        self.cfgs = [\n",
    "            # t, c, n, s\n",
    "            [1,  16, 1, 1],\n",
    "            [6,  24, 2, 2],\n",
    "            [6,  32, 3, 2],\n",
    "            [6,  64, 4, 2],\n",
    "            [6,  96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1],\n",
    "        ]\n",
    "\n",
    "        # building first layer\n",
    "        input_channel = _make_divisible(32 * width_mult, 4 if width_mult == 0.1 else 8)\n",
    "        layers = [conv_3x3_bn(3, input_channel, 2)]\n",
    "        # building inverted residual blocks\n",
    "        block = InvertedResidual\n",
    "        for t, c, n, s in self.cfgs:\n",
    "            output_channel = _make_divisible(c * width_mult, 4 if width_mult == 0.1 else 8)\n",
    "            for i in range(n):\n",
    "                layers.append(block(input_channel, output_channel, s if i == 0 else 1, t))\n",
    "                input_channel = output_channel\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        # building last several layers\n",
    "        output_channel = _make_divisible(1280 * width_mult, 4 if width_mult == 0.1 else 8) if width_mult > 1.0 else 1280\n",
    "        self.conv = conv_1x1_bn(input_channel, output_channel)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Linear(output_channel, num_classes)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "def mobilenetv2(**kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a MobileNet V2 model\n",
    "    \"\"\"\n",
    "    return MobileNetV2(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MobileNetV2()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the Inverted Residual Block\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, expand_ratio):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        hidden_dim = in_channels * expand_ratio\n",
    "        self.use_res_connect = (self.stride == 1 and in_channels == out_channels)\n",
    "\n",
    "        layers = []\n",
    "        if expand_ratio != 1:\n",
    "            # Pointwise expansion\n",
    "            layers.append(nn.Conv2d(in_channels, hidden_dim, kernel_size=1, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(hidden_dim))\n",
    "            layers.append(nn.ReLU6(inplace=True))\n",
    "        \n",
    "        # Depthwise convolution\n",
    "        layers.extend([\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=stride, padding=1, groups=hidden_dim, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            # Pointwise projection\n",
    "            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        ])\n",
    "\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "# Define the MobileNetV2 model\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=1000, width_mult=1.0):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        # Configuration of the inverted residual blocks (t, c, n, s)\n",
    "        # t: expansion factor, c: output channels, n: number of times to repeat, s: stride\n",
    "        self.cfgs = [\n",
    "            # (expand_ratio, output_channels, num_blocks, stride)\n",
    "            (1, 16, 1, 1),\n",
    "            (6, 24, 2, 2),\n",
    "            (6, 32, 3, 2),\n",
    "            (6, 64, 4, 2),\n",
    "            (6, 96, 3, 1),\n",
    "            (6, 160, 3, 2),\n",
    "            (6, 320, 1, 1),\n",
    "        ]\n",
    "\n",
    "        # Initial layer\n",
    "        input_channel = int(32 * width_mult)\n",
    "        self.last_channel = int(1280 * width_mult)\n",
    "        self.features = [nn.Sequential(\n",
    "            nn.Conv2d(3, input_channel, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(input_channel),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        )]\n",
    "\n",
    "        # Building inverted residual blocks\n",
    "        for t, c, n, s in self.cfgs:\n",
    "            output_channel = int(c * width_mult)\n",
    "            for i in range(n):\n",
    "                stride = s if i == 0 else 1\n",
    "                self.features.append(InvertedResidual(input_channel, output_channel, stride, expand_ratio=t))\n",
    "                input_channel = output_channel\n",
    "        \n",
    "        # Final layers\n",
    "        self.features.append(nn.Sequential(\n",
    "            nn.Conv2d(input_channel, self.last_channel, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(self.last_channel),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        ))\n",
    "\n",
    "        # Combine all layers\n",
    "        self.features = nn.Sequential(*self.features)\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.last_channel, num_classes)\n",
    "        )\n",
    "\n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "#         x = F.adaptive_avg_pool2d(x, 1).reshape(x.shape[0], -1)\n",
    "        x = self.avg_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "#         x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MobileNetV2(num_classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote = None\n",
    "if env.TARGET not in [\"sim\", \"tsim\", \"intelfocl\"]:\n",
    "\n",
    "    # Get remote from tracker node if environment variable is set.\n",
    "    # To set up the tracker, you'll need to follow the \"Auto-tuning\n",
    "    # a convolutional network for VTA\" tutorial.\n",
    "    tracker_host = os.environ.get(\"TVM_TRACKER_HOST\", None)\n",
    "    tracker_port = os.environ.get(\"TVM_TRACKER_PORT\", None)\n",
    "    # Otherwise if you have a device you want to program directly from\n",
    "    # the host, make sure you've set the variables below to the IP of\n",
    "    # your board.\n",
    "#     device_host = os.environ.get(\"VTA_RPC_HOST\", \"192.168.2.99\")\n",
    "#     device_host=\"10.42.0.32\"\n",
    "    device_host = \"10.42.0.188\"\n",
    "#     device_host=\"10.100.86.111\"\n",
    "    device_port = os.environ.get(\"VTA_RPC_PORT\", \"9091\")\n",
    "    if not tracker_host or not tracker_port:\n",
    "        remote = rpc.connect(device_host, int(device_port))\n",
    "    else:\n",
    "        remote = autotvm.measure.request_remote(\n",
    "            env.TARGET, tracker_host, int(tracker_port), timeout=10000\n",
    "        )\n",
    "\n",
    "    # Reconfigure the JIT runtime and FPGA.\n",
    "    # You can program the FPGA with your own custom bitstream\n",
    "    # by passing the path to the bitstream file instead of None.\n",
    "    reconfig_start = time.time()\n",
    "    vta.reconfig_runtime(remote)\n",
    "    #vta.program_fpga(remote, bitstream=\"/home/srchand/Desktop/research/TVM_Intel_Fork/tvm/vta/sri_scripts/bitstreams/vta_il_apm.bit\")\n",
    "    #vta.program_fpga(remote, bitstream=\"/home/srchand/Desktop/research/bitstreams/vta_trojan.bit\")\n",
    "    #vta.program_fpga(remote, bitstream=None)\n",
    "    #vta.program_fpga(remote, bitstream=\"/home/srchand/Desktop/research/TVM_Intel_Fork/tvm/vta/sri_scripts/bitstreams/vta_zcu104_trojan_wrapper.bit\")\n",
    "    #vta.program_fpga(remote, bitstream=\"/home/srchand/Desktop/research/TVM_Intel_Fork/tvm/vta/sri_scripts/bitstreams/vta_zcu104_ro_ref_clk_en_dis.bit\")\n",
    "#     vta.program_fpga(remote, bitstream=\"/mnt/hgfs/vmware_ubuntu_sf/bitstreams/vta_axi_sniffer_uart_rx_tx_hex.bit\")\n",
    "#     vta.program_fpga(remote, bitstream=\"/mnt/hgfs/vmware_ubuntu_sf/bitstreams/vta_ro_6m_no_axi_final_final.bit\")\n",
    "#     vta.program_fpga(remote, bitstream=\"/mnt/hgfs/vmware_ubuntu_sf/bitstreams/vta_pynq_sniffer_reset_on_read.bit\")\n",
    "#     vta.program_fpga(remote, bitstream='/mnt/hgfs/vmware_ubuntu_sf/vta_4x8x8/vta_1x8x32_Acc18_memory_trojan_runtime_sampling.bit')\n",
    "#     vta.program_fpga(remote, bitstream='/mnt/hgfs/vmware_ubuntu_sf/vta_4x8x8/vta_new_4x8x8_memory_trojan_runtime_sampling.bit')\n",
    "    vta.program_fpga(remote, bitstream='/mnt/hgfs/vmware_ubuntu_sf/vta_4x8x8/vta_new_1x16x16_memory_trojan_runtime_sampling.bit')\n",
    "\n",
    "#     vta.program_fpga(remote, bitstream='/mnt/hgfs/vmware_ubuntu_sf/vta_4x8x8/vta_2x16x16_memory_trojan_runtime_sampling.bit')\n",
    "    reconfig_time = time.time() - reconfig_start\n",
    "    print(\"Reconfigured FPGA and RPC runtime in {0:.2f}s!\".format(reconfig_time))\n",
    "\n",
    "# In simulation mode, host the RPC server locally.\n",
    "else:\n",
    "    remote = rpc.LocalSession()\n",
    "\n",
    "    if env.TARGET in [\"intelfocl\"]:\n",
    "        # program intelfocl aocx\n",
    "        vta.program_fpga(remote, bitstream=\"vta.bitstream\")\n",
    "\n",
    "# Get execution context from remote\n",
    "ctx = remote.ext_dev(0) if device == \"vta\" else remote.cpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# schedule_log_files = glob.glob(r'../logs/tuning_logs/vta_2x16x16/*.log')\n",
    "# schedule_log_files = glob.glob(r'../logs/tuning_logs/*.log')\n",
    "# schedule_log_files = glob.glob(r'../logs/tuning_logs/vta_1x8x32/*.log')\n",
    "# schedule_log_files = glob.glob(r'../logs/tuning_logs/vta_4x8x8/*.log')\n",
    "schedule_log_files = glob.glob(r'../logs/tuning_logs/vta_1x16x16/*.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-configured AutoTVM schedules\n",
    "with autotvm.tophub.context(target, extra_files=schedule_log_files):\n",
    "# with autotvm.tophub.context(target):\n",
    "\n",
    "    \n",
    "    input_name = \"input0\"\n",
    "\n",
    "    # Populate the shape and data type dictionary for ImageNet classifier input\n",
    "    dtype_dict = {input_name: \"float32\"}\n",
    "    shape_dict = {input_name: (env.BATCH, 3, 224, 224)}\n",
    "\n",
    "\n",
    "#     # Get off the shelf gluon model, and convert to relay\n",
    "#     gluon_model = vision.get_model(model, pretrained=True)\n",
    "    \n",
    "    \n",
    "#     pytorch_model = getattr(torchvision.models, model)(pretrained=True).eval()\n",
    "    \n",
    "        \n",
    "    input_shape = [env.BATCH, 3, 224, 224]\n",
    "    input_data = torch.randn(input_shape)\n",
    "    scripted_model = torch.jit.trace(net, input_data)\n",
    "    \n",
    "    shape_list = [(input_name, input_shape)]\n",
    "\n",
    "\n",
    "    # Measure build start time\n",
    "    build_start = time.time()\n",
    "\n",
    "#     Start front end compilation\n",
    "    mod, params = relay.frontend.from_pytorch(scripted_model, shape_list)\n",
    "    \n",
    "    \n",
    "#     mod, params = relay.frontend.from_mxnet(gluon_model, shape_dict)\n",
    "\n",
    "#     #mod, params = relay.frontend.from_mxnet(net, shape_dict)\n",
    "    \n",
    "#     # Update shape and type dictionary\n",
    "    shape_dict.update({k: v.shape for k, v in params.items()})\n",
    "    dtype_dict.update({k: str(v.dtype) for k, v in params.items()})\n",
    "    \n",
    "\n",
    "    if target.device_name == \"vta\":\n",
    "        # Perform quantization in Relay\n",
    "        # Note: We set opt_level to 3 in order to fold batch norm\n",
    "        with tvm.transform.PassContext(opt_level=3):\n",
    "            with relay.quantize.qconfig(global_scale=8.0, skip_conv_layers=[0]):\n",
    "                mod = relay.quantize.quantize(mod, params=params)\n",
    "#                 print(mod.astext(show_meta_data=False))\n",
    "#                 print(apput)\n",
    "            # Perform graph packing and constant folding for VTA target\n",
    "#             assert env.BLOCK_IN == env.BLOCK_OUT\n",
    "            # do device annotation if target is intelfocl or sim\n",
    "            relay_prog = graph_pack(\n",
    "                mod[\"main\"],\n",
    "                env.BATCH,\n",
    "                env.BLOCK_IN,\n",
    "                env.BLOCK_OUT,\n",
    "                env.WGT_WIDTH,\n",
    "#                 start_name=pack_dict[model][0],\n",
    "#                 stop_name='cast',\n",
    "#                 stop_name_idx=114,\n",
    "#                 stop_name=pack_dict[model][1],\n",
    "#                 start_name='nn.relu',\n",
    "#                 start_name_idx=2,\n",
    "                stop_name='nn.adaptive_avg_pool2d',\n",
    "                start_name=\"cast\",\n",
    "                start_name_idx=7,\n",
    "#                 stop_name=\"cast\",                \n",
    "#                 stop_name_idx=557,\n",
    "                device_annot=(env.TARGET == \"intelfocl\"),\n",
    "            )\n",
    "    else:\n",
    "        relay_prog = mod[\"main\"]\n",
    "\n",
    "    # Compile Relay program with AlterOpLayout disabled\n",
    "    if target.device_name != \"vta\":\n",
    "        with tvm.transform.PassContext(opt_level=3, disabled_pass={\"AlterOpLayout\"}):\n",
    "            graph, lib, params = relay.build(\n",
    "                relay_prog, target=target, params=params, target_host=env.target_host\n",
    "            )\n",
    "    else:\n",
    "        if env.TARGET == \"intelfocl\":\n",
    "            # multiple targets to run both on cpu and vta\n",
    "            target = {\"cpu\": env.target_vta_cpu, \"ext_dev\": target}\n",
    "        with vta.build_config(opt_level=3, disabled_pass={\"AlterOpLayout\"}):\n",
    "            graph, lib, params = relay.build(\n",
    "                relay_prog, target=target, params=params, target_host=env.target_host\n",
    "            )\n",
    "\n",
    "    # Measure Relay build time\n",
    "    build_time = time.time() - build_start\n",
    "    print(model + \" inference graph built in {0:.2f}s!\".format(build_time))\n",
    "\n",
    "    # Send the inference library over to the remote RPC server\n",
    "    temp = utils.tempdir()\n",
    "    lib.export_library(temp.relpath(\"graphlib.tar\"))\n",
    "    remote.upload(temp.relpath(\"graphlib.tar\"))\n",
    "    lib = remote.load_module(\"graphlib.tar\")\n",
    "\n",
    "    if env.TARGET == \"intelfocl\":\n",
    "        ctxes = [remote.ext_dev(0), remote.cpu(0)]\n",
    "        m = graph_runtime.create(graph, lib, ctxes)\n",
    "    else:\n",
    "        # Graph runtime\n",
    "        m = graph_runtime.create(graph, lib, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mod.astext(show_meta_data=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_url = \"https://github.com/uwsampl/web-data/raw/main/vta/models/\"\n",
    "categ_fn = \"synset.txt\"\n",
    "download.download(join(categ_url, categ_fn), categ_fn)\n",
    "synset = eval(open(categ_fn).read())\n",
    "\n",
    "# Download test image\n",
    "image_url = \"https://homes.cs.washington.edu/~moreau/media/vta/cat.jpg\"\n",
    "image_fn = \"cat.png\"\n",
    "download.download(image_url, image_fn)\n",
    "\n",
    "# Prepare test image for inference\n",
    "image = Image.open(image_fn).resize((224, 224))\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = np.array(image) - np.array([123.0, 117.0, 104.0])\n",
    "image /= np.array([58.395, 57.12, 57.375])\n",
    "image = image.transpose((2, 0, 1))\n",
    "image = image[np.newaxis, :]\n",
    "image = np.repeat(image, env.BATCH, axis=0)\n",
    "\n",
    "# Set the network parameters and inputs\n",
    "m.set_input(**params)\n",
    "m.set_input(input_name, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#p = mp.Process(target=read_apm, args=('bob',))\n",
    "#t1 = tr.Thread(target=read_apm, args=('bob',))\n",
    "#pool = mp.Pool(4)\n",
    "# Download ImageNet categories\n",
    "\n",
    "\n",
    "# Perform inference and gather execution statistics\n",
    "# More on: :py:method:`tvm.runtime.Module.time_evaluator`\n",
    "num = 4  # number of times we run module for a single measurement\n",
    "rep = 3  # number of measurements (we derive std dev from this)\n",
    "\n",
    "\n",
    "timer = m.module.time_evaluator(\"run\", ctx, number=num, repeat=rep)\n",
    "\n",
    "stds = []\n",
    "means = []\n",
    "\n",
    "#timer = m.module.time_evaluator(\"run\", ctx, number=num, repeat=rep)\n",
    "#\n",
    "\n",
    "if env.TARGET in [\"sim\", \"tsim\"]:\n",
    "    simulator.clear_stats()\n",
    "    timer()\n",
    "    sim_stats = simulator.stats()\n",
    "    print(\"\\nExecution statistics:\")\n",
    "    for k, v in sim_stats.items():\n",
    "        # Since we execute the workload many times, we need to normalize stats\n",
    "        # Note that there is always one warm up run\n",
    "        # Therefore we divide the overall stats by (num * rep + 1)\n",
    "        print(\"\\t{:<16}: {:>16}\".format(k, v // (num * rep + 1)))\n",
    "else:\n",
    "    #vta.init_apm(remote)\n",
    "#     for i in range(100):\n",
    "#         vta.start_power_monitor(remote,1e-6)\n",
    "\n",
    "#      tcost = timer()\n",
    "#     vta.start_power_monitor(remote,1e-6)\n",
    "    m.run()\n",
    "#     vta.stop_power_monitor(remote,f'/home/xilinx/i2c_prog/pmbus_recordings/1x8x32_resnet18/resnet18_pmbus_1x8x32.csv')\n",
    "#         vta.stop_power_monitor(remote,f'/home/xilinx/i2c_prog/pmbus_recordings/power_readings_pmbus_1x16x16_{i}.csv')\n",
    "#         std = np.std(tcost.results) * 1000\n",
    "#         mean = tcost.mean * 1000\n",
    "#         stds.append(std)\n",
    "#         means.append(mean)\n",
    "#     print(\"\\nPerformed inference in %.2fms (std = %.2f) for %d samples\" % (mean, std, env.BATCH))\n",
    "#     print(\"Average per sample inference time: %.2fms\" % (mean / env.BATCH))\n",
    "\n",
    "    #vta.read_metrics(remote,0)\n",
    "#     m.run()\n",
    "#     tcost = timer()\n",
    "#     std = np.std(tcost.results) * 1000\n",
    "#     mean = tcost.mean * 1000\n",
    "#     print(\"\\nPerformed inference in %.2fms (std = %.2f) for %d samples\" % (mean, std, env.BATCH))\n",
    "#     print(\"Average per sample inference time: %.2fms\" % (mean / env.BATCH))\n",
    "    \n",
    "#     vta.reset_ro_monitor(remote)\n",
    "#     vta.start_ro_monitor(remote)\n",
    "#     m.run()\n",
    "#     tcost = timer()\n",
    "\n",
    "#     vta.stop_ro_monitor(remote,0)\n",
    "#     #vta.reset_apm(remote)\n",
    "        \n",
    "\n",
    "# print(\"done\")\n",
    "    # Get classification results\n",
    "tvm_output = m.get_output(0, tvm.nd.empty((env.BATCH, 1000), \"float32\", remote.cpu(0)))\n",
    "for b in range(env.BATCH):\n",
    "    top_categories = np.argsort(tvm_output.asnumpy()[b])\n",
    "    # Report top-5 classification results\n",
    "    print(\"\\n{} prediction for sample {}\".format(model, b))\n",
    "    print(\"\\t#1:\", synset[top_categories[-1]])\n",
    "    print(\"\\t#2:\", synset[top_categories[-2]])\n",
    "    print(\"\\t#3:\", synset[top_categories[-3]])\n",
    "    print(\"\\t#4:\", synset[top_categories[-4]])\n",
    "    print(\"\\t#5:\", synset[top_categories[-5]])\n",
    "    # This just checks that one of the 5 top categories\n",
    "    # is one variety of cat; this is by no means an accurate\n",
    "    # assessment of how quantization affects classification\n",
    "    # accuracy but is meant to catch changes to the\n",
    "    # quantization pass that would accuracy in the CI.\n",
    "    cat_detected = False\n",
    "    for k in top_categories[-5:]:\n",
    "        if \"cat\" in synset[k]:\n",
    "            cat_detected = True\n",
    "    assert cat_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(tvm.runtime.Module.time_evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import signal\n",
    "\n",
    "\n",
    "# proc = subprocess.Popen([\"sshpass\", \"-p\", \"xilinx\", \"ssh\", \"-t\", \"xilinx@{}\".format(device_host), \"echo\", \"\\\"data\\\"\", \"tmp_ro_csvs/test.csv\"], \n",
    "#                         stdout=subprocess.PIPE, \n",
    "#                         stderr=subprocess.PIPE,)\n",
    "\n",
    "proc = subprocess.Popen([\"sshpass\", \"-p\", \"xilinx\", \"ssh\", \"-t\", \"xilinx@{}\".format(device_host), \"sudo\", \"python3\",\n",
    "                             \"/home/xilinx/tvm_il/vta/python/vta/read_trojan.py\", \"--base-address\", \"0xa0010000\", \"--offset\", \"0x0008\", \"--poll\", \"--auto-stop\", \">>\",\"tmp_ro_csvs/test.csv\"], \n",
    "                        stdout=subprocess.PIPE, \n",
    "                        stderr=subprocess.PIPE,)\n",
    "\n",
    "\n",
    "#                         shell=True, preexec_fn=os.setsid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = subprocess.Popen([\"sshpass\", \"-p\", \"xilinx\", \"scp\", \"xilinx@{}:/home/xilinx/tmp_ro_csvs/test.csv\".format(device_host), \"./\"], \n",
    "                        stdout=subprocess.PIPE, \n",
    "                        stderr=subprocess.PIPE,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = subprocess.Popen([\"sshpass\", \"-p\", \"xilinx\", \"ssh\",\"-t\", \"xilinx@{}\".format(device_host), \"rm\",\"tmp_ro_csvs/*\"],\n",
    "                        stdout=subprocess.PIPE, \n",
    "                        stderr=subprocess.PIPE,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = proc.stdout.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readings = []\n",
    "for line in lines:\n",
    "    line.decode(\"utf-8\")\n",
    "    readings.append(int(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(readings, columns=['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tvm-build-il-2] *",
   "language": "python",
   "name": "conda-env-tvm-build-il-2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
