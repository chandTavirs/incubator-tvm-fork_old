{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tvm import relay\n",
    "import tvm\n",
    "from collections import namedtuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Workload = namedtuple(\n",
    "    \"Conv2DWorkload\",\n",
    "    [\n",
    "        \"batch\",\n",
    "        \"height\",\n",
    "        \"width\",\n",
    "        \"in_filter\",\n",
    "        \"out_filter\",\n",
    "        \"hkernel\",\n",
    "        \"wkernel\",\n",
    "        \"hpad\",\n",
    "        \"wpad\",\n",
    "        \"hstride\",\n",
    "        \"wstride\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "channels_re = re.compile('.*Tensor\\[\\(([\\d]+), ([\\d]+), [\\d]+, [\\d]+\\).*padding.*Tensor\\[\\([\\d]+, [\\d]+, ([\\d]+), ([\\d]+)\\).*')\n",
    "cast_re = re.compile('cast.*Tensor\\[\\([\\d]+, [\\d]+, ([\\d]+), ([\\d]+)\\).*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_final = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_wkls(model):\n",
    "    count=0\n",
    "    pytorch_model = torch.hub.load('pytorch/vision', model, pretrained=True)\n",
    "    pytorch_model.eval()\n",
    "    workloads = []\n",
    "    for layer in pytorch_model.modules():\n",
    "        if type(layer) == torch.nn.modules.conv.Conv2d:\n",
    "            if(layer.in_channels % 16 == 0 and layer.out_channels % 16 ==0 and layer.padding[0] == layer.padding[1]):\n",
    "                workloads.append(Workload(1, 0, 0, layer.in_channels, layer.out_channels,\n",
    "                                  layer.kernel_size[0], layer.kernel_size[1], layer.padding[0], layer.padding[1]\n",
    "                                 , layer.stride[0], layer.stride[1]))\n",
    "    input_shape = [1, 3, 299, 299]\n",
    "    input_data = torch.randn(input_shape)\n",
    "    scripted_model = torch.jit.trace(pytorch_model, input_data).eval()\n",
    "    shape_list = [(\"input0\", input_shape)]\n",
    "    mod, params = relay.frontend.from_pytorch(scripted_model, shape_list)\n",
    "    with tvm.transform.PassContext(opt_level=3):\n",
    "        with relay.quantize.qconfig(global_scale=8.0, skip_conv_layers=[0]):\n",
    "             mod = relay.quantize.quantize(mod, params=params)\n",
    "                \n",
    "    mod_as_string = mod.astext(show_meta_data=False)\n",
    "    cast_line = \"\"\n",
    "    cast_line_idx = -1\n",
    "    final_workloads = []\n",
    "    for i, line in enumerate(mod_as_string.split('\\n')):\n",
    "        if \"cast\" in line and \"int8\" in line:\n",
    "            cast_line = line\n",
    "            cast_line_idx = i\n",
    "        elif \"conv2d\" in line and \"int8\" in line:\n",
    "            match = re.search(channels_re, line)\n",
    "            if match:\n",
    "                if int(match.group(1)) % 16 == 0 and int(match.group(2)) % 16 == 0:\n",
    "                    match_cast = re.search(cast_re, cast_line)\n",
    "                    if match_cast:\n",
    "                        wkl = workloads[count]\n",
    "                        final_workloads.append(\n",
    "                        'Workload({}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {})'.format(\n",
    "                        1, match_cast.group(1), match_cast.group(2), wkl.in_filter, wkl.out_filter,\n",
    "                        wkl.hkernel,wkl.wkernel, wkl.hpad, wkl.wpad, wkl.hstride, wkl.wstride))\n",
    "                        count += 1\n",
    "    \n",
    "    return final_workloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/srchand/.cache/torch/hub/pytorch_vision_main\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-fe7eab995214>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_wkls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inception_v3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-dde32f0dae5d>\u001b[0m in \u001b[0;36mextract_wkls\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mmatch_cast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_re\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcast_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmatch_cast\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                         \u001b[0mwkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkloads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                         final_workloads.append(\n\u001b[1;32m     37\u001b[0m                         'Workload({}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {})'.format(\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "final_final.extend(extract_wkls(\"inception_v3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('workloads_0', Workload(1, 149, 149, 32, 32, 3, 3, 0, 0, 1, 1)),\n",
      "('workloads_1', Workload(1, 147, 147, 32, 64, 3, 3, 1, 1, 1, 1)),\n",
      "('workloads_2', Workload(1, 73, 73, 64, 80, 1, 1, 0, 0, 1, 1)),\n",
      "('workloads_3', Workload(1, 73, 73, 80, 192, 3, 3, 0, 0, 1, 1)),\n",
      "('workloads_4', Workload(1, 35, 35, 192, 64, 1, 1, 0, 0, 1, 1)),\n",
      "('workloads_5', Workload(1, 35, 35, 192, 48, 1, 1, 0, 0, 1, 1)),\n",
      "('workloads_6', Workload(1, 35, 35, 48, 64, 5, 5, 2, 2, 1, 1)),\n",
      "('workloads_7', Workload(1, 35, 35, 64, 96, 3, 3, 1, 1, 1, 1)),\n",
      "('workloads_8', Workload(1, 35, 35, 96, 96, 3, 3, 1, 1, 1, 1)),\n",
      "('workloads_9', Workload(1, 35, 35, 192, 32, 1, 1, 0, 0, 1, 1)),\n",
      "('workloads_10', Workload(1, 35, 35, 256, 64, 1, 1, 0, 0, 1, 1)),\n",
      "('workloads_11', Workload(1, 35, 35, 256, 48, 1, 1, 0, 0, 1, 1)),\n",
      "('workloads_12', Workload(1, 35, 35, 288, 64, 1, 1, 0, 0, 1, 1)),\n",
      "('workloads_13', Workload(1, 35, 35, 288, 48, 1, 1, 0, 0, 1, 1)),\n",
      "('workloads_14', Workload(1, 35, 35, 288, 384, 3, 3, 0, 0, 2, 2)),\n",
      "('workloads_15', Workload(1, 35, 35, 96, 96, 3, 3, 0, 0, 2, 2)),\n",
      "('workloads_16', Workload(1, 17, 17, 768, 192, 1, 1, 0, 0, 1, 1)),\n",
      "('workloads_17', Workload(1, 17, 17, 768, 128, 1, 1, 0, 0, 1, 1)),\n",
      "('workloads_18', Workload(1, 17, 17, 128, 128, 1, 7, 0, 3, 1, 1)),\n",
      "('workloads_19', Workload(1, 17, 17, 128, 192, 7, 1, 3, 0, 1, 1)),\n",
      "('workloads_20', Workload(1, 17, 17, 128, 128, 7, 1, 3, 0, 1, 1)),\n",
      "('workloads_21', Workload(1, 17, 17, 128, 192, 1, 7, 0, 3, 1, 1)),\n",
      "('workloads_22', Workload(1, 17, 17, 768, 160, 1, 1, 0, 0, 1, 1)),\n",
      "('workloads_23', Workload(1, 17, 17, 160, 160, 1, 7, 0, 3, 1, 1)),\n",
      "('workloads_24', Workload(1, 17, 17, 160, 192, 7, 1, 3, 0, 1, 1)),\n",
      "('workloads_25', Workload(1, 17, 17, 160, 160, 7, 1, 3, 0, 1, 1)),\n",
      "('workloads_26', Workload(1, 17, 17, 160, 192, 1, 7, 0, 3, 1, 1)),\n",
      "('workloads_27', Workload(1, 17, 17, 192, 192, 1, 7, 0, 3, 1, 1)),\n",
      "('workloads_28', Workload(1, 17, 17, 192, 192, 7, 1, 3, 0, 1, 1)),\n",
      "('workloads_29', Workload(1, 17, 17, 128, 768, 5, 5, 0, 0, 1, 1)),\n",
      "('workloads_30', Workload(1, 17, 17, 192, 320, 3, 3, 0, 0, 2, 2)),\n",
      "('workloads_31', Workload(1, 8, 8, 192, 192, 7, 1, 3, 0, 1, 1)),\n",
      "('workloads_32', Workload(1, 8, 8, 192, 192, 3, 3, 0, 0, 2, 2)),\n",
      "('workloads_33', Workload(1, 8, 8, 1280, 320, 1, 1, 0, 0, 1, 1)),\n",
      "('workloads_34', Workload(1, 8, 8, 1280, 384, 1, 1, 0, 0, 1, 1)),\n",
      "('workloads_35', Workload(1, 8, 8, 384, 384, 1, 3, 0, 1, 1, 1)),\n",
      "('workloads_36', Workload(1, 8, 8, 384, 384, 3, 1, 1, 0, 1, 1)),\n",
      "('workloads_37', Workload(1, 8, 8, 1280, 448, 1, 1, 0, 0, 1, 1)),\n",
      "('workloads_38', Workload(1, 8, 8, 448, 384, 3, 3, 1, 1, 1, 1)),\n",
      "('workloads_39', Workload(1, 8, 8, 1280, 192, 1, 1, 0, 0, 1, 1)),\n",
      "('workloads_40', Workload(1, 8, 8, 2048, 320, 1, 1, 0, 0, 1, 1)),\n",
      "('workloads_41', Workload(1, 8, 8, 2048, 384, 1, 1, 0, 0, 1, 1)),\n",
      "('workloads_42', Workload(1, 8, 8, 2048, 448, 1, 1, 0, 0, 1, 1)),\n"
     ]
    }
   ],
   "source": [
    "final_final = list(dict.fromkeys(final_final))\n",
    "for i, wkl in enumerate(final_final):\n",
    "    print('(\\'workloads_{}\\', {}),'.format(i, wkl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
