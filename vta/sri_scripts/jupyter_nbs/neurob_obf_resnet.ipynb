{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srchand/anaconda3/envs/tvm-build-il-2/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/srchand/anaconda3/envs/tvm-build-il-2/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, print_function\n",
    "\n",
    "import argparse, json, os, requests, sys, time\n",
    "from io import BytesIO\n",
    "from os.path import join, isfile\n",
    "from PIL import Image\n",
    "\n",
    "from mxnet.gluon.model_zoo import vision\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tvm\n",
    "from tvm import te\n",
    "from tvm import rpc, autotvm, relay\n",
    "from tvm.contrib import graph_runtime, utils, download\n",
    "from tvm.contrib.debugger import debug_runtime\n",
    "from tvm.relay import transform\n",
    "\n",
    "import vta\n",
    "from vta.testing import simulator\n",
    "from vta.top import graph_pack\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from tvm.contrib.download import download_testdata\n",
    "from neurob_obf_models import custom_cnn_9\n",
    "\n",
    "\n",
    "\n",
    "# Make sure that TVM was compiled with RPC=1\n",
    "assert tvm.runtime.enabled(\"rpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VTA parameters from the 3rdparty/vta-hw/config/vta_config.json file\n",
    "env = vta.get_env()\n",
    "\n",
    "# Set ``device=arm_cpu`` to run inference on the CPU\n",
    "# or ``device=vta`` to run inference on the FPGA.\n",
    "device = \"vta\"\n",
    "target = env.target if device == \"vta\" else env.target_vta_cpu\n",
    "\n",
    "# Dictionary lookup for when to start/end bit packing\n",
    "pack_dict = {\n",
    "    \"resnet18_v1\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet18\": [\"nn.max_pool2d\", \"nn.adaptive_avg_pool2d\"],\n",
    "    \"resnet34\": [\"nn.max_pool2d\", \"nn.adaptive_avg_pool2d\"],\n",
    "    \"resnet50\": [\"nn.max_pool2d\", \"nn.adaptive_avg_pool2d\"],\n",
    "    \"resnet101\": [\"nn.max_pool2d\", \"nn.adaptive_avg_pool2d\"],\n",
    "    \"vgg11\": [\"nn.max_pool2d\", \"nn.dense\"],\n",
    "    \"vgg16\":    [\"nn.max_pool2d\", \"nn.dense\"],\n",
    "    \"resnet34_v1\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet18_v2\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet34_v2\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet50_v2\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet101_v2\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"mobilenetv2_1.0\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"]\n",
    "}\n",
    "\n",
    "# Name of Gluon model to compile\n",
    "# The ``start_pack`` and ``stop_pack`` labels indicate where\n",
    "# to start and end the graph packing relay pass: in other words\n",
    "# where to start and finish offloading to VTA.\n",
    "#model = \"resnet18_v1\"\n",
    "#assert model in pack_dict\n",
    "model = \"resnet18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote = None\n",
    "if env.TARGET not in [\"sim\", \"tsim\", \"intelfocl\"]:\n",
    "\n",
    "    # Get remote from tracker node if environment variable is set.\n",
    "    # To set up the tracker, you'll need to follow the \"Auto-tuning\n",
    "    # a convolutional network for VTA\" tutorial.\n",
    "    tracker_host = os.environ.get(\"TVM_TRACKER_HOST\", None)\n",
    "    tracker_port = os.environ.get(\"TVM_TRACKER_PORT\", None)\n",
    "    # Otherwise if you have a device you want to program directly from\n",
    "    # the host, make sure you've set the variables below to the IP of\n",
    "    # your board.\n",
    "#     device_host = os.environ.get(\"VTA_RPC_HOST\", \"192.168.2.99\")\n",
    "#     device_host=\"10.42.0.32\"\n",
    "    device_host = \"10.42.0.188\"\n",
    "#     device_host=\"10.100.86.111\"\n",
    "    device_port = os.environ.get(\"VTA_RPC_PORT\", \"9091\")\n",
    "    if not tracker_host or not tracker_port:\n",
    "        remote = rpc.connect(device_host, int(device_port))\n",
    "    else:\n",
    "        remote = autotvm.measure.request_remote(\n",
    "            env.TARGET, tracker_host, int(tracker_port), timeout=10000\n",
    "        )\n",
    "\n",
    "    # Reconfigure the JIT runtime and FPGA.\n",
    "    # You can program the FPGA with your own custom bitstream\n",
    "    # by passing the path to the bitstream file instead of None.\n",
    "    reconfig_start = time.time()\n",
    "    vta.reconfig_runtime(remote)\n",
    "    #vta.program_fpga(remote, bitstream=\"/home/srchand/Desktop/research/TVM_Intel_Fork/tvm/vta/sri_scripts/bitstreams/vta_il_apm.bit\")\n",
    "    #vta.program_fpga(remote, bitstream=\"/home/srchand/Desktop/research/bitstreams/vta_trojan.bit\")\n",
    "    #vta.program_fpga(remote, bitstream=None)\n",
    "    #vta.program_fpga(remote, bitstream=\"/home/srchand/Desktop/research/TVM_Intel_Fork/tvm/vta/sri_scripts/bitstreams/vta_zcu104_trojan_wrapper.bit\")\n",
    "    #vta.program_fpga(remote, bitstream=\"/home/srchand/Desktop/research/TVM_Intel_Fork/tvm/vta/sri_scripts/bitstreams/vta_zcu104_ro_ref_clk_en_dis.bit\")\n",
    "#     vta.program_fpga(remote, bitstream=\"/mnt/hgfs/vmware_ubuntu_sf/bitstreams/vta_axi_sniffer_uart_rx_tx_hex.bit\")\n",
    "#     vta.program_fpga(remote, bitstream=\"/mnt/hgfs/vmware_ubuntu_sf/bitstreams/vta_ro_6m_no_axi_final_final.bit\")\n",
    "#     vta.program_fpga(remote, bitstream=\"/mnt/hgfs/vmware_ubuntu_sf/bitstreams/vta_pynq_sniffer_reset_on_read.bit\")\n",
    "#     vta.program_fpga(remote, bitstream='/mnt/hgfs/vmware_ubuntu_sf/vta_4x8x8/vta_1x8x32_Acc18_memory_trojan_runtime_sampling.bit')\n",
    "#     vta.program_fpga(remote, bitstream='/mnt/hgfs/vmware_ubuntu_sf/vta_4x8x8/vta_new_4x8x8_memory_trojan_runtime_sampling.bit')\n",
    "    vta.program_fpga(remote, bitstream='/mnt/hgfs/vmware_ubuntu_sf/vta_4x8x8/vta_new_1x16x16_memory_trojan_runtime_sampling.bit')\n",
    "\n",
    "#     vta.program_fpga(remote, bitstream='/mnt/hgfs/vmware_ubuntu_sf/vta_4x8x8/vta_1x16x16_10000.bit')\n",
    "    reconfig_time = time.time() - reconfig_start\n",
    "    print(\"Reconfigured FPGA and RPC runtime in {0:.2f}s!\".format(reconfig_time))\n",
    "\n",
    "# In simulation mode, host the RPC server locally.\n",
    "else:\n",
    "    remote = rpc.LocalSession()\n",
    "\n",
    "    if env.TARGET in [\"intelfocl\"]:\n",
    "        # program intelfocl aocx\n",
    "        vta.program_fpga(remote, bitstream=\"vta.bitstream\")\n",
    "\n",
    "# Get execution context from remote\n",
    "ctx = remote.ext_dev(0) if device == \"vta\" else remote.cpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = 150528\n",
    "widen_list = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "decompo_list = [0, 0, 0, 0, 2, 0, 1, 1, 2, 0, 2, 0, 4, 0, 0, 4, 4, 0, 0, 0, 4]\n",
    "dummy_list = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "deepen_list = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0]\n",
    "skipcon_list = [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1]\n",
    "kerneladd_list = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "fuse_list = [10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 5.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 8.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 5.0, 10.0, 10.0, 10.0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
    "prune_list = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obf_model = custom_cnn_9(input_features, True, widen_list, decompo_list, dummy_list, deepen_list, skipcon_list,\n",
    "                kerneladd_list)\n",
    "\n",
    "X = torch.randn(env.BATCH, input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srchand/Desktop/research/TVM_Intel_Fork/tvm/vta/sri_scripts/jupyter_nbs/neurob_obf_models/model_10_obf.py:1517: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755853042/work/aten/src/ATen/native/BinaryOps.cpp:607.)\n",
      "  X1_0 = self.conv12_0(X1[:, :int(torch.floor_divide(X1_shape[1],4)), :, :])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0016, -0.0010, -0.0006, -0.0003,  0.0035, -0.0006,  0.0012, -0.0050,\n",
       "          0.0020, -0.0030]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obf_model.eval()\n",
    "obf_model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# schedule_log_files = glob.glob(r'../logs/tuning_logs/vta_2x16x16/*.log')\n",
    "# schedule_log_files = glob.glob(r'../logs/tuning_logs/*.log')\n",
    "# schedule_log_files = glob.glob(r'../logs/tuning_logs/vta_1x8x32/*.log')\n",
    "# schedule_log_files = glob.glob(r'../logs/tuning_logs/vta_4x8x8/*.log')\n",
    "schedule_log_files = glob.glob(r'../logs/tuning_logs/vta_1x16x16/*.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-configured AutoTVM schedules\n",
    "with autotvm.tophub.context(target, extra_files=schedule_log_files):\n",
    "# with autotvm.tophub.context(target):\n",
    "\n",
    "    \n",
    "    input_name = \"input0\"\n",
    "\n",
    "    # Populate the shape and data type dictionary for ImageNet classifier input\n",
    "    dtype_dict = {input_name: \"float32\"}\n",
    "    shape_dict = {input_name: (env.BATCH, 3, 224, 224)}\n",
    "\n",
    "\n",
    "#     # Get off the shelf gluon model, and convert to relay\n",
    "#     gluon_model = vision.get_model(model, pretrained=True)\n",
    "    \n",
    "    \n",
    "#     pytorch_model = getattr(torchvision.models, model)(pretrained=True).eval()\n",
    "    \n",
    "    pytorch_model = obf_model\n",
    "        \n",
    "    input_shape = [env.BATCH, 3, 224, 224]\n",
    "    input_data = torch.randn(input_shape)\n",
    "    scripted_model = torch.jit.trace(pytorch_model, input_data)\n",
    "    \n",
    "    shape_list = [(input_name, input_shape)]\n",
    "\n",
    "\n",
    "    # Measure build start time\n",
    "    build_start = time.time()\n",
    "\n",
    "#     Start front end compilation\n",
    "    mod, params = relay.frontend.from_pytorch(scripted_model, shape_list)\n",
    "    \n",
    "    \n",
    "#     mod, params = relay.frontend.from_mxnet(gluon_model, shape_dict)\n",
    "\n",
    "#     #mod, params = relay.frontend.from_mxnet(net, shape_dict)\n",
    "    \n",
    "#     # Update shape and type dictionary\n",
    "    shape_dict.update({k: v.shape for k, v in params.items()})\n",
    "    dtype_dict.update({k: str(v.dtype) for k, v in params.items()})\n",
    "    \n",
    "\n",
    "    if target.device_name == \"vta\":\n",
    "        # Perform quantization in Relay\n",
    "        # Note: We set opt_level to 3 in order to fold batch norm\n",
    "        with tvm.transform.PassContext(opt_level=3):\n",
    "            with relay.quantize.qconfig(global_scale=8.0, skip_conv_layers=[0]):\n",
    "                mod = relay.quantize.quantize(mod, params=params)\n",
    "                print(mod.astext(show_meta_data=False))\n",
    "#                 print(apput)\n",
    "            # Perform graph packing and constant folding for VTA target\n",
    "#             assert env.BLOCK_IN == env.BLOCK_OUT\n",
    "            # do device annotation if target is intelfocl or sim\n",
    "            relay_prog = graph_pack(\n",
    "                mod[\"main\"],\n",
    "                env.BATCH,\n",
    "                env.BLOCK_IN,\n",
    "                env.BLOCK_OUT,\n",
    "                env.WGT_WIDTH,\n",
    "                start_name=pack_dict[model][0],\n",
    "#                 stop_name='cast',\n",
    "#                 stop_name_idx=114,\n",
    "                stop_name=pack_dict[model][1],\n",
    "#                 start_name='nn.relu',\n",
    "#                 start_name_idx=2,\n",
    "#                 stop_name='nn.adaptive_avg_pool2d',\n",
    "#                 start_name=\"cast\",\n",
    "#                 start_name_idx=8,\n",
    "#                 stop_name=\"cast\",                \n",
    "#                 stop_name_idx=71,\n",
    "                device_annot=(env.TARGET == \"intelfocl\"),\n",
    "            )\n",
    "    else:\n",
    "        relay_prog = mod[\"main\"]\n",
    "\n",
    "    # Compile Relay program with AlterOpLayout disabled\n",
    "    if target.device_name != \"vta\":\n",
    "        with tvm.transform.PassContext(opt_level=3, disabled_pass={\"AlterOpLayout\"}):\n",
    "            graph, lib, params = relay.build(\n",
    "                relay_prog, target=target, params=params, target_host=env.target_host\n",
    "            )\n",
    "    else:\n",
    "        if env.TARGET == \"intelfocl\":\n",
    "            # multiple targets to run both on cpu and vta\n",
    "            target = {\"cpu\": env.target_vta_cpu, \"ext_dev\": target}\n",
    "        with vta.build_config(opt_level=3, disabled_pass={\"AlterOpLayout\"}):\n",
    "            graph, lib, params = relay.build(\n",
    "                relay_prog, target=target, params=params, target_host=env.target_host\n",
    "            )\n",
    "\n",
    "    # Measure Relay build time\n",
    "    build_time = time.time() - build_start\n",
    "    print(model + \" inference graph built in {0:.2f}s!\".format(build_time))\n",
    "\n",
    "    # Send the inference library over to the remote RPC server\n",
    "    temp = utils.tempdir()\n",
    "    lib.export_library(temp.relpath(\"graphlib.tar\"))\n",
    "    remote.upload(temp.relpath(\"graphlib.tar\"))\n",
    "    lib = remote.load_module(\"graphlib.tar\")\n",
    "\n",
    "    if env.TARGET == \"intelfocl\":\n",
    "        ctxes = [remote.ext_dev(0), remote.cpu(0)]\n",
    "        m = graph_runtime.create(graph, lib, ctxes)\n",
    "    else:\n",
    "        # Graph runtime\n",
    "        m = graph_runtime.create(graph, lib, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mod.astext(show_meta_data=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_url = \"https://github.com/uwsampl/web-data/raw/main/vta/models/\"\n",
    "categ_fn = \"synset.txt\"\n",
    "download.download(join(categ_url, categ_fn), categ_fn)\n",
    "synset = eval(open(categ_fn).read())\n",
    "\n",
    "# Download test image\n",
    "image_url = \"https://homes.cs.washington.edu/~moreau/media/vta/cat.jpg\"\n",
    "image_fn = \"cat.png\"\n",
    "download.download(image_url, image_fn)\n",
    "\n",
    "# Prepare test image for inference\n",
    "image = Image.open(image_fn).resize((224, 224))\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = np.array(image) - np.array([123.0, 117.0, 104.0])\n",
    "image /= np.array([58.395, 57.12, 57.375])\n",
    "image = image.transpose((2, 0, 1))\n",
    "image = image[np.newaxis, :]\n",
    "image = np.repeat(image, env.BATCH, axis=0)\n",
    "\n",
    "# Set the network parameters and inputs\n",
    "m.set_input(**params)\n",
    "m.set_input(input_name, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#p = mp.Process(target=read_apm, args=('bob',))\n",
    "#t1 = tr.Thread(target=read_apm, args=('bob',))\n",
    "#pool = mp.Pool(4)\n",
    "# Download ImageNet categories\n",
    "\n",
    "\n",
    "# Perform inference and gather execution statistics\n",
    "# More on: :py:method:`tvm.runtime.Module.time_evaluator`\n",
    "num = 4  # number of times we run module for a single measurement\n",
    "rep = 3  # number of measurements (we derive std dev from this)\n",
    "\n",
    "\n",
    "timer = m.module.time_evaluator(\"run\", ctx, number=num, repeat=rep)\n",
    "\n",
    "stds = []\n",
    "means = []\n",
    "\n",
    "#timer = m.module.time_evaluator(\"run\", ctx, number=num, repeat=rep)\n",
    "#\n",
    "\n",
    "if env.TARGET in [\"sim\", \"tsim\"]:\n",
    "    simulator.clear_stats()\n",
    "    timer()\n",
    "    sim_stats = simulator.stats()\n",
    "    print(\"\\nExecution statistics:\")\n",
    "    for k, v in sim_stats.items():\n",
    "        # Since we execute the workload many times, we need to normalize stats\n",
    "        # Note that there is always one warm up run\n",
    "        # Therefore we divide the overall stats by (num * rep + 1)\n",
    "        print(\"\\t{:<16}: {:>16}\".format(k, v // (num * rep + 1)))\n",
    "else:\n",
    "    #vta.init_apm(remote)\n",
    "#     for i in range(100):\n",
    "#         vta.start_power_monitor(remote,1e-6)\n",
    "\n",
    "#      tcost = timer()\n",
    "#     vta.start_power_monitor(remote,1e-6)\n",
    "#     vta.remote_cmd_exec(remote)\n",
    "    m.run()\n",
    "#     vta.stop_power_monitor(remote,f'/home/xilinx/i2c_prog/resnet18_1x16x16.csv')\n",
    "#         vta.stop_power_monitor(remote,f'/home/xilinx/i2c_prog/pmbus_recordings/power_readings_pmbus_1x16x16_{i}.csv')\n",
    "#         std = np.std(tcost.results) * 1000\n",
    "#         mean = tcost.mean * 1000\n",
    "#         stds.append(std)\n",
    "#         means.append(mean)\n",
    "#     print(\"\\nPerformed inference in %.2fms (std = %.2f) for %d samples\" % (mean, std, env.BATCH))\n",
    "#     print(\"Average per sample inference time: %.2fms\" % (mean / env.BATCH))\n",
    "\n",
    "    #vta.read_metrics(remote,0)\n",
    "#     m.run()\n",
    "#     tcost = timer()\n",
    "#     std = np.std(tcost.results) * 1000\n",
    "#     mean = tcost.mean * 1000\n",
    "#     print(\"\\nPerformed inference in %.2fms (std = %.2f) for %d samples\" % (mean, std, env.BATCH))\n",
    "#     print(\"Average per sample inference time: %.2fms\" % (mean / env.BATCH))\n",
    "    \n",
    "#     vta.reset_ro_monitor(remote)\n",
    "#     vta.start_ro_monitor(remote)\n",
    "#     m.run()\n",
    "#     tcost = timer()\n",
    "\n",
    "#     vta.stop_ro_monitor(remote,0)\n",
    "#     #vta.reset_apm(remote)\n",
    "        \n",
    "\n",
    "# print(\"done\")\n",
    "    # Get classification results\n",
    "tvm_output = m.get_output(0, tvm.nd.empty((env.BATCH, 1000), \"float32\", remote.cpu(0)))\n",
    "for b in range(env.BATCH):\n",
    "    top_categories = np.argsort(tvm_output.asnumpy()[b])\n",
    "    # Report top-5 classification results\n",
    "    print(\"\\n{} prediction for sample {}\".format(model, b))\n",
    "    print(\"\\t#1:\", synset[top_categories[-1]])\n",
    "    print(\"\\t#2:\", synset[top_categories[-2]])\n",
    "    print(\"\\t#3:\", synset[top_categories[-3]])\n",
    "    print(\"\\t#4:\", synset[top_categories[-4]])\n",
    "    print(\"\\t#5:\", synset[top_categories[-5]])\n",
    "    # This just checks that one of the 5 top categories\n",
    "    # is one variety of cat; this is by no means an accurate\n",
    "    # assessment of how quantization affects classification\n",
    "    # accuracy but is meant to catch changes to the\n",
    "    # quantization pass that would accuracy in the CI.\n",
    "    cat_detected = False\n",
    "    for k in top_categories[-5:]:\n",
    "        if \"cat\" in synset[k]:\n",
    "            cat_detected = True\n",
    "    assert cat_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(tvm.runtime.Module.time_evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import signal\n",
    "\n",
    "\n",
    "# proc = subprocess.Popen([\"sshpass\", \"-p\", \"xilinx\", \"ssh\", \"-t\", \"xilinx@{}\".format(device_host), \"echo\", \"\\\"data\\\"\", \"tmp_ro_csvs/test.csv\"], \n",
    "#                         stdout=subprocess.PIPE, \n",
    "#                         stderr=subprocess.PIPE,)\n",
    "\n",
    "proc = subprocess.Popen([\"sshpass\", \"-p\", \"xilinx\", \"ssh\", \"-t\", \"xilinx@{}\".format(device_host), \"sudo\", \"python3\",\n",
    "                             \"/home/xilinx/tvm_il/vta/python/vta/read_trojan.py\", \"--base-address\", \"0xa0010000\", \"--offset\", \"0x0008\", \"--poll\", \"--auto-stop\", \">>\",\"tmp_ro_csvs/test.csv\"], \n",
    "                        stdout=subprocess.PIPE, \n",
    "                        stderr=subprocess.PIPE,)\n",
    "\n",
    "\n",
    "#                         shell=True, preexec_fn=os.setsid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = subprocess.Popen([\"sshpass\", \"-p\", \"xilinx\", \"scp\", \"xilinx@{}:/home/xilinx/tmp_ro_csvs/test.csv\".format(device_host), \"./\"], \n",
    "                        stdout=subprocess.PIPE, \n",
    "                        stderr=subprocess.PIPE,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = subprocess.Popen([\"sshpass\", \"-p\", \"xilinx\", \"ssh\",\"-t\", \"xilinx@{}\".format(device_host), \"rm\",\"tmp_ro_csvs/*\"],\n",
    "                        stdout=subprocess.PIPE, \n",
    "                        stderr=subprocess.PIPE,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = proc.stdout.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readings = []\n",
    "for line in lines:\n",
    "    line.decode(\"utf-8\")\n",
    "    readings.append(int(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(readings, columns=['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tvm-build-il-2] *",
   "language": "python",
   "name": "conda-env-tvm-build-il-2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
