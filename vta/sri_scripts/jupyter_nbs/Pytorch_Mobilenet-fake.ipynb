{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, print_function\n",
    "\n",
    "import argparse, json, os, requests, sys, time\n",
    "from io import BytesIO\n",
    "from os.path import join, isfile\n",
    "from PIL import Image\n",
    "\n",
    "from mxnet.gluon.model_zoo import vision\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tvm\n",
    "from tvm import te\n",
    "from tvm import rpc, autotvm, relay\n",
    "from tvm.contrib import graph_runtime, utils, download\n",
    "from tvm.contrib.debugger import debug_runtime\n",
    "from tvm.relay import transform\n",
    "\n",
    "import vta\n",
    "from vta.testing import simulator\n",
    "from vta.top import graph_pack\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from tvm.contrib.download import download_testdata\n",
    "\n",
    "\n",
    "\n",
    "# Make sure that TVM was compiled with RPC=1\n",
    "assert tvm.runtime.enabled(\"rpc\")\n",
    "import os\n",
    "os.environ[\"TVM_BACKTRACE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VTA parameters from the 3rdparty/vta-hw/config/vta_config.json file\n",
    "env = vta.get_env()\n",
    "\n",
    "# Set ``device=arm_cpu`` to run inference on the CPU\n",
    "# or ``device=vta`` to run inference on the FPGA.\n",
    "device = \"vta\"\n",
    "target = env.target if device == \"vta\" else env.target_vta_cpu\n",
    "\n",
    "# Dictionary lookup for when to start/end bit packing\n",
    "pack_dict = {\n",
    "    \"resnet18_v1\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet18\": [\"nn.max_pool2d\", \"nn.adaptive_avg_pool2d\"],\n",
    "    \"resnet34\": [\"nn.max_pool2d\", \"nn.adaptive_avg_pool2d\"],\n",
    "    \"resnet50\": [\"nn.max_pool2d\", \"nn.adaptive_avg_pool2d\"],\n",
    "    \"resnet101\": [\"nn.max_pool2d\", \"nn.adaptive_avg_pool2d\"],\n",
    "    \"vgg11\": [\"nn.max_pool2d\", \"nn.dense\"],\n",
    "    \"vgg16\":    [\"nn.max_pool2d\", \"nn.dense\"],\n",
    "    \"resnet34_v1\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet18_v2\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet34_v2\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet50_v2\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet101_v2\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"mobilenetv2_1.0\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"]\n",
    "}\n",
    "\n",
    "# Name of Gluon model to compile\n",
    "# The ``start_pack`` and ``stop_pack`` labels indicate where\n",
    "# to start and end the graph packing relay pass: in other words\n",
    "# where to start and finish offloading to VTA.\n",
    "#model = \"resnet18_v1\"\n",
    "#assert model in pack_dict\n",
    "model = \"mobilenetv2_1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from torch import nn\n",
    "\n",
    "class ModelFromCSV(nn.Module):\n",
    "    def __init__(self, csv_path='../mnetv2_config.csv', num_classes=10):\n",
    "        super(ModelFromCSV, self).__init__()\n",
    "\n",
    "        with open(csv_path, newline='') as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            layers = []\n",
    "\n",
    "            for i, row in enumerate(reader):\n",
    "                if i == 0:\n",
    "                    continue\n",
    "                if i == 1:\n",
    "                    layers.append(nn.Conv2d(3, int(row[2]), kernel_size=3, stride=2, padding=1))\n",
    "                    layers.append(nn.BatchNorm2d(int(row[2])))\n",
    "                    layers.append(nn.ReLU6(inplace=True))\n",
    "                # check if csv file has layer type column\n",
    "                if len(row) == 10:\n",
    "                    if row[9] == 'C':\n",
    "                        layers.append(nn.Conv2d(int(row[2]), int(row[8]), kernel_size=int(row[3]), stride=int(row[4]), padding=int(row[5])))\n",
    "                    elif row[9] == 'D':\n",
    "                        layers.append(nn.Conv2d(int(row[2]), int(row[8]), kernel_size=int(row[3]), stride=int(row[4]), padding=int(row[5]), groups=int(row[8])))\n",
    "                else:\n",
    "                    # if input channel = output channel, do depthwise separable convolution\n",
    "                    if row[2] == row[8]:\n",
    "                        layers.append(nn.Conv2d(int(row[2]), int(row[8]), kernel_size=int(row[3]), stride=int(row[4]), padding=int(row[5]), groups=int(row[8])))\n",
    "                    else:\n",
    "                        layers.append(nn.Conv2d(int(row[2]), int(row[8]), kernel_size=int(row[3]), stride=int(row[4]), padding=int(row[5])))\n",
    "                layers.append(nn.BatchNorm2d(int(row[8])))\n",
    "                layers.append(nn.ReLU6(inplace=True))\n",
    "\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # classifier with input features same as output of last conv layer\n",
    "        self.classifier = nn.Sequential(nn.Linear(int(row[8]), 4096), nn.ReLU6(inplace=True), nn.Dropout(),\n",
    "                                        # nn.Linear(4096, 4096), nn.ReLU(inplace=True), nn.Dropout(),\n",
    "                                        nn.Linear(4096, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "#         x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "net = ModelFromCSV('/home/srchand/Desktop/research/Adversarial_Attack/re_fake_configs/mnetv2_config_100352_dconv2d_pred.csv',num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelFromCSV(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU6(inplace=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU6(inplace=True)\n",
       "    (6): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU6(inplace=True)\n",
       "    (9): Conv2d(16, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU6(inplace=True)\n",
       "    (12): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96)\n",
       "    (13): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU6(inplace=True)\n",
       "    (15): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (16): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU6(inplace=True)\n",
       "    (18): Conv2d(32, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU6(inplace=True)\n",
       "    (21): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144)\n",
       "    (22): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (23): ReLU6(inplace=True)\n",
       "    (24): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU6(inplace=True)\n",
       "    (27): Conv2d(32, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU6(inplace=True)\n",
       "    (30): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144)\n",
       "    (31): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU6(inplace=True)\n",
       "    (33): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (34): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (35): ReLU6(inplace=True)\n",
       "    (36): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (37): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (38): ReLU6(inplace=True)\n",
       "    (39): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "    (40): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (41): ReLU6(inplace=True)\n",
       "    (42): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (44): ReLU6(inplace=True)\n",
       "    (45): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (46): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (47): ReLU6(inplace=True)\n",
       "    (48): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "    (49): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (50): ReLU6(inplace=True)\n",
       "    (51): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (52): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (53): ReLU6(inplace=True)\n",
       "    (54): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (55): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (56): ReLU6(inplace=True)\n",
       "    (57): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192)\n",
       "    (58): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (59): ReLU6(inplace=True)\n",
       "    (60): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (62): ReLU6(inplace=True)\n",
       "    (63): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (64): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (65): ReLU6(inplace=True)\n",
       "    (66): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "    (67): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (68): ReLU6(inplace=True)\n",
       "    (69): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (70): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (71): ReLU6(inplace=True)\n",
       "    (72): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (73): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (74): ReLU6(inplace=True)\n",
       "    (75): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "    (76): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (77): ReLU6(inplace=True)\n",
       "    (78): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (79): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (80): ReLU6(inplace=True)\n",
       "    (81): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (82): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (83): ReLU6(inplace=True)\n",
       "    (84): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "    (85): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (86): ReLU6(inplace=True)\n",
       "    (87): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (88): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (89): ReLU6(inplace=True)\n",
       "    (90): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (91): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (92): ReLU6(inplace=True)\n",
       "    (93): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "    (94): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (95): ReLU6(inplace=True)\n",
       "    (96): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (97): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (98): ReLU6(inplace=True)\n",
       "    (99): Conv2d(96, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (100): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (101): ReLU6(inplace=True)\n",
       "    (102): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)\n",
       "    (103): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (104): ReLU6(inplace=True)\n",
       "    (105): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (106): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (107): ReLU6(inplace=True)\n",
       "    (108): Conv2d(96, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (109): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (110): ReLU6(inplace=True)\n",
       "    (111): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)\n",
       "    (112): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (113): ReLU6(inplace=True)\n",
       "    (114): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (115): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (116): ReLU6(inplace=True)\n",
       "    (117): Conv2d(96, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (118): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (119): ReLU6(inplace=True)\n",
       "    (120): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576)\n",
       "    (121): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (122): ReLU6(inplace=True)\n",
       "    (123): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (124): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (125): ReLU6(inplace=True)\n",
       "    (126): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (127): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (128): ReLU6(inplace=True)\n",
       "    (129): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960)\n",
       "    (130): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (131): ReLU6(inplace=True)\n",
       "    (132): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (133): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (134): ReLU6(inplace=True)\n",
       "    (135): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (136): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (137): ReLU6(inplace=True)\n",
       "    (138): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960)\n",
       "    (139): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (140): ReLU6(inplace=True)\n",
       "    (141): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (142): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (143): ReLU6(inplace=True)\n",
       "    (144): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (145): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (146): ReLU6(inplace=True)\n",
       "    (147): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960)\n",
       "    (148): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (149): ReLU6(inplace=True)\n",
       "    (150): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (151): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (152): ReLU6(inplace=True)\n",
       "    (153): Conv2d(320, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (154): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (155): ReLU6(inplace=True)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1280, out_features=4096, bias=True)\n",
       "    (1): ReLU6(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote = None\n",
    "if env.TARGET not in [\"sim\", \"tsim\", \"intelfocl\"]:\n",
    "\n",
    "    # Get remote from tracker node if environment variable is set.\n",
    "    # To set up the tracker, you'll need to follow the \"Auto-tuning\n",
    "    # a convolutional network for VTA\" tutorial.\n",
    "    tracker_host = os.environ.get(\"TVM_TRACKER_HOST\", None)\n",
    "    tracker_port = os.environ.get(\"TVM_TRACKER_PORT\", None)\n",
    "    # Otherwise if you have a device you want to program directly from\n",
    "    # the host, make sure you've set the variables below to the IP of\n",
    "    # your board.\n",
    "#     device_host = os.environ.get(\"VTA_RPC_HOST\", \"192.168.2.99\")\n",
    "#     device_host=\"10.42.0.32\"\n",
    "    device_host = \"10.42.0.188\"\n",
    "#     device_host=\"10.100.86.111\"\n",
    "    device_port = os.environ.get(\"VTA_RPC_PORT\", \"9091\")\n",
    "    if not tracker_host or not tracker_port:\n",
    "        remote = rpc.connect(device_host, int(device_port))\n",
    "    else:\n",
    "        remote = autotvm.measure.request_remote(\n",
    "            env.TARGET, tracker_host, int(tracker_port), timeout=10000\n",
    "        )\n",
    "\n",
    "    # Reconfigure the JIT runtime and FPGA.\n",
    "    # You can program the FPGA with your own custom bitstream\n",
    "    # by passing the path to the bitstream file instead of None.\n",
    "    reconfig_start = time.time()\n",
    "    vta.reconfig_runtime(remote)\n",
    "    #vta.program_fpga(remote, bitstream=\"/home/srchand/Desktop/research/TVM_Intel_Fork/tvm/vta/sri_scripts/bitstreams/vta_il_apm.bit\")\n",
    "    #vta.program_fpga(remote, bitstream=\"/home/srchand/Desktop/research/bitstreams/vta_trojan.bit\")\n",
    "    #vta.program_fpga(remote, bitstream=None)\n",
    "    #vta.program_fpga(remote, bitstream=\"/home/srchand/Desktop/research/TVM_Intel_Fork/tvm/vta/sri_scripts/bitstreams/vta_zcu104_trojan_wrapper.bit\")\n",
    "    #vta.program_fpga(remote, bitstream=\"/home/srchand/Desktop/research/TVM_Intel_Fork/tvm/vta/sri_scripts/bitstreams/vta_zcu104_ro_ref_clk_en_dis.bit\")\n",
    "#     vta.program_fpga(remote, bitstream=\"/mnt/hgfs/vmware_ubuntu_sf/bitstreams/vta_axi_sniffer_uart_rx_tx_hex.bit\")\n",
    "#     vta.program_fpga(remote, bitstream=\"/mnt/hgfs/vmware_ubuntu_sf/bitstreams/vta_ro_6m_no_axi_final_final.bit\")\n",
    "#     vta.program_fpga(remote, bitstream=\"/mnt/hgfs/vmware_ubuntu_sf/bitstreams/vta_pynq_sniffer_reset_on_read.bit\")\n",
    "#     vta.program_fpga(remote, bitstream='/mnt/hgfs/vmware_ubuntu_sf/vta_4x8x8/vta_1x8x32_Acc18_memory_trojan_runtime_sampling.bit')\n",
    "#     vta.program_fpga(remote, bitstream='/mnt/hgfs/vmware_ubuntu_sf/vta_4x8x8/vta_new_4x8x8_memory_trojan_runtime_sampling.bit')\n",
    "#     vta.program_fpga(remote, bitstream='/mnt/hgfs/vmware_ubuntu_sf/vta_4x8x8/vta_new_1x16x16_memory_trojan_runtime_sampling.bit')\n",
    "\n",
    "#     vta.program_fpga(remote, bitstream='/mnt/hgfs/vmware_ubuntu_sf/vta_4x8x8/vta_2x16x16_memory_trojan_runtime_sampling.bit')\n",
    "    reconfig_time = time.time() - reconfig_start\n",
    "    print(\"Reconfigured FPGA and RPC runtime in {0:.2f}s!\".format(reconfig_time))\n",
    "\n",
    "# In simulation mode, host the RPC server locally.\n",
    "else:\n",
    "    remote = rpc.LocalSession()\n",
    "\n",
    "    if env.TARGET in [\"intelfocl\"]:\n",
    "        # program intelfocl aocx\n",
    "        vta.program_fpga(remote, bitstream=\"vta.bitstream\")\n",
    "\n",
    "# Get execution context from remote\n",
    "ctx = remote.ext_dev(0) if device == \"vta\" else remote.cpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# schedule_log_files = glob.glob(r'../logs/tuning_logs/vta_2x16x16/*.log')\n",
    "# schedule_log_files = glob.glob(r'../logs/tuning_logs/*.log')\n",
    "# schedule_log_files = glob.glob(r'../logs/tuning_logs/vta_1x8x32/*.log')\n",
    "# schedule_log_files = glob.glob(r'../logs/tuning_logs/vta_4x8x8/*.log')\n",
    "schedule_log_files = glob.glob(r'../logs/tuning_logs/vta_1x16x16/*.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-configured AutoTVM schedules\n",
    "with autotvm.tophub.context(target, extra_files=schedule_log_files):\n",
    "# with autotvm.tophub.context(target):\n",
    "\n",
    "    \n",
    "    input_name = \"input0\"\n",
    "\n",
    "    # Populate the shape and data type dictionary for ImageNet classifier input\n",
    "    dtype_dict = {input_name: \"float32\"}\n",
    "    shape_dict = {input_name: (env.BATCH, 3, 224, 224)}\n",
    "\n",
    "\n",
    "#     # Get off the shelf gluon model, and convert to relay\n",
    "#     gluon_model = vision.get_model(model, pretrained=True)\n",
    "    \n",
    "    \n",
    "#     pytorch_model = getattr(torchvision.models, model)(pretrained=True).eval()\n",
    "    \n",
    "        \n",
    "    input_shape = [env.BATCH, 3, 224, 224]\n",
    "    input_data = torch.randn(input_shape)\n",
    "    scripted_model = torch.jit.trace(net, input_data)\n",
    "    \n",
    "    shape_list = [(input_name, input_shape)]\n",
    "\n",
    "\n",
    "    # Measure build start time\n",
    "    build_start = time.time()\n",
    "\n",
    "#     Start front end compilation\n",
    "    mod, params = relay.frontend.from_pytorch(scripted_model, shape_list)\n",
    "    \n",
    "    \n",
    "#     mod, params = relay.frontend.from_mxnet(gluon_model, shape_dict)\n",
    "\n",
    "#     #mod, params = relay.frontend.from_mxnet(net, shape_dict)\n",
    "    \n",
    "#     # Update shape and type dictionary\n",
    "    shape_dict.update({k: v.shape for k, v in params.items()})\n",
    "    dtype_dict.update({k: str(v.dtype) for k, v in params.items()})\n",
    "    \n",
    "\n",
    "    if target.device_name == \"vta\":\n",
    "        # Perform quantization in Relay\n",
    "        # Note: We set opt_level to 3 in order to fold batch norm\n",
    "        with tvm.transform.PassContext(opt_level=3):\n",
    "            with relay.quantize.qconfig(global_scale=8.0, skip_conv_layers=[0]):\n",
    "                mod = relay.quantize.quantize(mod, params=params)\n",
    "#                 print(mod.astext(show_meta_data=False))\n",
    "#                 print(apput)\n",
    "            # Perform graph packing and constant folding for VTA target\n",
    "#             assert env.BLOCK_IN == env.BLOCK_OUT\n",
    "            # do device annotation if target is intelfocl or sim\n",
    "            relay_prog = graph_pack(\n",
    "                mod[\"main\"],\n",
    "                env.BATCH,\n",
    "                env.BLOCK_IN,\n",
    "                env.BLOCK_OUT,\n",
    "                env.WGT_WIDTH,\n",
    "#                 start_name=pack_dict[model][0],\n",
    "#                 stop_name='cast',\n",
    "#                 stop_name_idx=114,\n",
    "#                 stop_name=pack_dict[model][1],\n",
    "#                 start_name='nn.relu',\n",
    "#                 start_name_idx=2,\n",
    "                stop_name='nn.adaptive_avg_pool2d',\n",
    "                start_name=\"cast\",\n",
    "                start_name_idx=10,\n",
    "#                 stop_name=\"cast\",                \n",
    "#                 stop_name_idx=557,\n",
    "                device_annot=(env.TARGET == \"intelfocl\"),\n",
    "            )\n",
    "    else:\n",
    "        relay_prog = mod[\"main\"]\n",
    "\n",
    "    # Compile Relay program with AlterOpLayout disabled\n",
    "    if target.device_name != \"vta\":\n",
    "        with tvm.transform.PassContext(opt_level=3, disabled_pass={\"AlterOpLayout\"}):\n",
    "            graph, lib, params = relay.build(\n",
    "                relay_prog, target=target, params=params, target_host=env.target_host\n",
    "            )\n",
    "    else:\n",
    "        if env.TARGET == \"intelfocl\":\n",
    "            # multiple targets to run both on cpu and vta\n",
    "            target = {\"cpu\": env.target_vta_cpu, \"ext_dev\": target}\n",
    "        with vta.build_config(opt_level=3, disabled_pass={\"AlterOpLayout\"}):\n",
    "            graph, lib, params = relay.build(\n",
    "                relay_prog, target=target, params=params, target_host=env.target_host\n",
    "            )\n",
    "\n",
    "    # Measure Relay build time\n",
    "    build_time = time.time() - build_start\n",
    "    print(model + \" inference graph built in {0:.2f}s!\".format(build_time))\n",
    "\n",
    "    # Send the inference library over to the remote RPC server\n",
    "    temp = utils.tempdir()\n",
    "    lib.export_library(temp.relpath(\"graphlib.tar\"))\n",
    "    remote.upload(temp.relpath(\"graphlib.tar\"))\n",
    "    lib = remote.load_module(\"graphlib.tar\")\n",
    "\n",
    "    if env.TARGET == \"intelfocl\":\n",
    "        ctxes = [remote.ext_dev(0), remote.cpu(0)]\n",
    "        m = graph_runtime.create(graph, lib, ctxes)\n",
    "    else:\n",
    "        # Graph runtime\n",
    "        m = graph_runtime.create(graph, lib, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mod.astext(show_meta_data=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_url = \"https://github.com/uwsampl/web-data/raw/main/vta/models/\"\n",
    "categ_fn = \"synset.txt\"\n",
    "download.download(join(categ_url, categ_fn), categ_fn)\n",
    "synset = eval(open(categ_fn).read())\n",
    "\n",
    "# Download test image\n",
    "image_url = \"https://homes.cs.washington.edu/~moreau/media/vta/cat.jpg\"\n",
    "image_fn = \"cat.png\"\n",
    "download.download(image_url, image_fn)\n",
    "\n",
    "# Prepare test image for inference\n",
    "image = Image.open(image_fn).resize((224, 224))\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = np.array(image) - np.array([123.0, 117.0, 104.0])\n",
    "image /= np.array([58.395, 57.12, 57.375])\n",
    "image = image.transpose((2, 0, 1))\n",
    "image = image[np.newaxis, :]\n",
    "image = np.repeat(image, env.BATCH, axis=0)\n",
    "\n",
    "# Set the network parameters and inputs\n",
    "m.set_input(**params)\n",
    "m.set_input(input_name, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#p = mp.Process(target=read_apm, args=('bob',))\n",
    "#t1 = tr.Thread(target=read_apm, args=('bob',))\n",
    "#pool = mp.Pool(4)\n",
    "# Download ImageNet categories\n",
    "\n",
    "\n",
    "# Perform inference and gather execution statistics\n",
    "# More on: :py:method:`tvm.runtime.Module.time_evaluator`\n",
    "num = 4  # number of times we run module for a single measurement\n",
    "rep = 3  # number of measurements (we derive std dev from this)\n",
    "\n",
    "\n",
    "timer = m.module.time_evaluator(\"run\", ctx, number=num, repeat=rep)\n",
    "\n",
    "stds = []\n",
    "means = []\n",
    "\n",
    "#timer = m.module.time_evaluator(\"run\", ctx, number=num, repeat=rep)\n",
    "#\n",
    "\n",
    "if env.TARGET in [\"sim\", \"tsim\"]:\n",
    "    simulator.clear_stats()\n",
    "    timer()\n",
    "    sim_stats = simulator.stats()\n",
    "    print(\"\\nExecution statistics:\")\n",
    "    for k, v in sim_stats.items():\n",
    "        # Since we execute the workload many times, we need to normalize stats\n",
    "        # Note that there is always one warm up run\n",
    "        # Therefore we divide the overall stats by (num * rep + 1)\n",
    "        print(\"\\t{:<16}: {:>16}\".format(k, v // (num * rep + 1)))\n",
    "else:\n",
    "    #vta.init_apm(remote)\n",
    "#     for i in range(100):\n",
    "#         vta.start_power_monitor(remote,1e-6)\n",
    "\n",
    "#      tcost = timer()\n",
    "#     vta.start_power_monitor(remote,1e-6)\n",
    "    m.run()\n",
    "#     vta.stop_power_monitor(remote,f'/home/xilinx/i2c_prog/pmbus_recordings/1x8x32_resnet18/resnet18_pmbus_1x8x32.csv')\n",
    "#         vta.stop_power_monitor(remote,f'/home/xilinx/i2c_prog/pmbus_recordings/power_readings_pmbus_1x16x16_{i}.csv')\n",
    "#         std = np.std(tcost.results) * 1000\n",
    "#         mean = tcost.mean * 1000\n",
    "#         stds.append(std)\n",
    "#         means.append(mean)\n",
    "#     print(\"\\nPerformed inference in %.2fms (std = %.2f) for %d samples\" % (mean, std, env.BATCH))\n",
    "#     print(\"Average per sample inference time: %.2fms\" % (mean / env.BATCH))\n",
    "\n",
    "    #vta.read_metrics(remote,0)\n",
    "#     m.run()\n",
    "#     tcost = timer()\n",
    "#     std = np.std(tcost.results) * 1000\n",
    "#     mean = tcost.mean * 1000\n",
    "#     print(\"\\nPerformed inference in %.2fms (std = %.2f) for %d samples\" % (mean, std, env.BATCH))\n",
    "#     print(\"Average per sample inference time: %.2fms\" % (mean / env.BATCH))\n",
    "    \n",
    "#     vta.reset_ro_monitor(remote)\n",
    "#     vta.start_ro_monitor(remote)\n",
    "#     m.run()\n",
    "#     tcost = timer()\n",
    "\n",
    "#     vta.stop_ro_monitor(remote,0)\n",
    "#     #vta.reset_apm(remote)\n",
    "        \n",
    "\n",
    "# print(\"done\")\n",
    "    # Get classification results\n",
    "tvm_output = m.get_output(0, tvm.nd.empty((env.BATCH, 1000), \"float32\", remote.cpu(0)))\n",
    "for b in range(env.BATCH):\n",
    "    top_categories = np.argsort(tvm_output.asnumpy()[b])\n",
    "    # Report top-5 classification results\n",
    "    print(\"\\n{} prediction for sample {}\".format(model, b))\n",
    "    print(\"\\t#1:\", synset[top_categories[-1]])\n",
    "    print(\"\\t#2:\", synset[top_categories[-2]])\n",
    "    print(\"\\t#3:\", synset[top_categories[-3]])\n",
    "    print(\"\\t#4:\", synset[top_categories[-4]])\n",
    "    print(\"\\t#5:\", synset[top_categories[-5]])\n",
    "    # This just checks that one of the 5 top categories\n",
    "    # is one variety of cat; this is by no means an accurate\n",
    "    # assessment of how quantization affects classification\n",
    "    # accuracy but is meant to catch changes to the\n",
    "    # quantization pass that would accuracy in the CI.\n",
    "    cat_detected = False\n",
    "    for k in top_categories[-5:]:\n",
    "        if \"cat\" in synset[k]:\n",
    "            cat_detected = True\n",
    "    assert cat_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(tvm.runtime.Module.time_evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import signal\n",
    "\n",
    "\n",
    "# proc = subprocess.Popen([\"sshpass\", \"-p\", \"xilinx\", \"ssh\", \"-t\", \"xilinx@{}\".format(device_host), \"echo\", \"\\\"data\\\"\", \"tmp_ro_csvs/test.csv\"], \n",
    "#                         stdout=subprocess.PIPE, \n",
    "#                         stderr=subprocess.PIPE,)\n",
    "\n",
    "proc = subprocess.Popen([\"sshpass\", \"-p\", \"xilinx\", \"ssh\", \"-t\", \"xilinx@{}\".format(device_host), \"sudo\", \"python3\",\n",
    "                             \"/home/xilinx/tvm_il/vta/python/vta/read_trojan.py\", \"--base-address\", \"0xa0010000\", \"--offset\", \"0x0008\", \"--poll\", \"--auto-stop\", \">>\",\"tmp_ro_csvs/test.csv\"], \n",
    "                        stdout=subprocess.PIPE, \n",
    "                        stderr=subprocess.PIPE,)\n",
    "\n",
    "\n",
    "#                         shell=True, preexec_fn=os.setsid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = subprocess.Popen([\"sshpass\", \"-p\", \"xilinx\", \"scp\", \"xilinx@{}:/home/xilinx/tmp_ro_csvs/test.csv\".format(device_host), \"./\"], \n",
    "                        stdout=subprocess.PIPE, \n",
    "                        stderr=subprocess.PIPE,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = subprocess.Popen([\"sshpass\", \"-p\", \"xilinx\", \"ssh\",\"-t\", \"xilinx@{}\".format(device_host), \"rm\",\"tmp_ro_csvs/*\"],\n",
    "                        stdout=subprocess.PIPE, \n",
    "                        stderr=subprocess.PIPE,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = proc.stdout.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readings = []\n",
    "for line in lines:\n",
    "    line.decode(\"utf-8\")\n",
    "    readings.append(int(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(readings, columns=['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tvm-build-il-2] *",
   "language": "python",
   "name": "conda-env-tvm-build-il-2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
